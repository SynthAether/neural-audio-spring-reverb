Using device: cuda:0
Using configuration gcn-1047-c00
Dilations: [1, 512]
Configuration name: gcn-1047-c00
Receptive field: 50275 samples or 1047.4 ms
Parameters: 211.584 k
Using losses: STFTLoss and SmoothL1Loss
Total dataset samples: 690
Training model for 1000 epochs, current epoch 0
Epoch 0: Loss improved from  inf to 1.426715 - > Saving model
Epoch 1: Loss improved from 1.426715 to 1.221982 - > Saving model
Epoch 2: Loss improved from 1.221982 to 1.127163 - > Saving model
Epoch 3: Loss improved from 1.127163 to 1.109131 - > Saving model
Epoch 4: Loss improved from 1.109131 to 1.050338 - > Saving model
Epoch 5: Loss improved from 1.050338 to 1.032497 - > Saving model
Epoch 6: Loss improved from 1.032497 to 1.020355 - > Saving model
Epoch 10: Loss improved from 1.020355 to 1.006973 - > Saving model
Epoch 11: Loss improved from 1.006973 to 1.004069 - > Saving model
Epoch 13: Loss improved from 1.004069 to 0.995029 - > Saving model
Epoch 15: Loss improved from 0.995029 to 0.991258 - > Saving model
Epoch 20: Loss improved from 0.991258 to 0.983709 - > Saving model
Epoch 27: Loss improved from 0.983709 to 0.980686 - > Saving model
Epoch 28: Loss improved from 0.980686 to 0.976877 - > Saving model
Epoch 31: Loss improved from 0.976877 to 0.971092 - > Saving model
Epoch 36: Loss improved from 0.971092 to 0.968139 - > Saving model
Epoch 39: Loss improved from 0.968139 to 0.961408 - > Saving model
Epoch 56: Loss improved from 0.961408 to 0.960250 - > Saving model
Epoch 57: Loss improved from 0.960250 to 0.959083 - > Saving model
Epoch 64: Loss improved from 0.959083 to 0.953705 - > Saving model
Epoch 74: Loss improved from 0.953705 to 0.947895 - > Saving model
Epoch 00096: reducing learning rate of group 0 to 1.0000e-04.
Epoch 96: Loss improved from 0.947895 to 0.941988 - > Saving model
Epoch 101: Loss improved from 0.941988 to 0.939972 - > Saving model
Epoch 104: Loss improved from 0.939972 to 0.939396 - > Saving model
Epoch 116: Loss improved from 0.939396 to 0.939091 - > Saving model
Epoch 118: Loss improved from 0.939091 to 0.938287 - > Saving model
Epoch 00140: reducing learning rate of group 0 to 1.0000e-05.
Epoch 142: Loss improved from 0.938287 to 0.938009 - > Saving model
Epoch 144: Loss improved from 0.938009 to 0.937947 - > Saving model
Epoch 149: Loss improved from 0.937947 to 0.937781 - > Saving model
Epoch 00171: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00192: reducing learning rate of group 0 to 1.0000e-07.
Epoch 194: Loss improved from 0.937781 to 0.937551 - > Saving model
Epoch 00216: reducing learning rate of group 0 to 1.0000e-08.
Epoch 294: Loss did not improve for 100 epochs, stopping training
Epoch 294, final validation loss: 0.9380002582774443
