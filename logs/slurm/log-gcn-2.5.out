Using device: cuda:0
Using configuration gcn-2.5
Dilations: [1, 2, 4, 8, 16, 32]
Configuration name: gcn-2.5
Receptive field: 127 samples or 2.6 ms
Parameters: 40.320 k
Using losses: STFTLoss and SmoothL1Loss
Total dataset samples: 690
Training model for 1000 epochs, current epoch 0
Epoch 0: Loss improved from  inf to 1.229100 - > Saving model
Epoch 1: Loss improved from 1.229100 to 1.205693 - > Saving model
Epoch 2: Loss improved from 1.205693 to 1.159222 - > Saving model
Epoch 5: Loss improved from 1.159222 to 1.149266 - > Saving model
Epoch 7: Loss improved from 1.149266 to 1.135528 - > Saving model
Epoch 11: Loss improved from 1.135528 to 1.133703 - > Saving model
Epoch 13: Loss improved from 1.133703 to 1.122781 - > Saving model
Epoch 15: Loss improved from 1.122781 to 1.115412 - > Saving model
Epoch 18: Loss improved from 1.115412 to 1.094034 - > Saving model
Epoch 35: Loss improved from 1.094034 to 1.085058 - > Saving model
Epoch 00057: reducing learning rate of group 0 to 1.0000e-04.
Epoch 57: Loss improved from 1.085058 to 1.083910 - > Saving model
Epoch 58: Loss improved from 1.083910 to 1.082992 - > Saving model
Epoch 59: Loss improved from 1.082992 to 1.080300 - > Saving model
Epoch 60: Loss improved from 1.080300 to 1.077745 - > Saving model
Epoch 67: Loss improved from 1.077745 to 1.076266 - > Saving model
Epoch 79: Loss improved from 1.076266 to 1.075884 - > Saving model
Epoch 84: Loss improved from 1.075884 to 1.075330 - > Saving model
Epoch 98: Loss improved from 1.075330 to 1.074234 - > Saving model
Epoch 104: Loss improved from 1.074234 to 1.074088 - > Saving model
Epoch 106: Loss improved from 1.074088 to 1.073700 - > Saving model
Epoch 00128: reducing learning rate of group 0 to 1.0000e-05.
Epoch 132: Loss improved from 1.073700 to 1.073578 - > Saving model
Epoch 00154: reducing learning rate of group 0 to 1.0000e-06.
Epoch 155: Loss improved from 1.073578 to 1.073319 - > Saving model
Epoch 162: Loss improved from 1.073319 to 1.073009 - > Saving model
Epoch 166: Loss improved from 1.073009 to 1.072914 - > Saving model
Epoch 00184: reducing learning rate of group 0 to 1.0000e-07.
Epoch 204: Loss improved from 1.072914 to 1.072792 - > Saving model
Epoch 00226: reducing learning rate of group 0 to 1.0000e-08.
Epoch 283: Loss improved from 1.072792 to 1.072693 - > Saving model
Epoch 383: Loss did not improve for 100 epochs, stopping training
Epoch 383, final validation loss: 1.0760802977225359
