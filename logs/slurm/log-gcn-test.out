Using device: cuda:0
Using configuration gcn-test
Configuration name: gcn-test
Receptive field: 361 samples or 7.5 ms
Parameters: 89.088 k
Using losses: STFTLoss and SmoothL1Loss
Total dataset samples: 690
Training model for 1000 epochs, current epoch 0
Epoch 0: Loss improved from  inf to 1.590997 - > Saving model
Epoch 1: Loss improved from 1.590997 to 1.202090 - > Saving model
Epoch 2: Loss improved from 1.202090 to 1.168567 - > Saving model
Epoch 5: Loss improved from 1.168567 to 1.149909 - > Saving model
Epoch 7: Loss improved from 1.149909 to 1.134585 - > Saving model
Epoch 13: Loss improved from 1.134585 to 1.124705 - > Saving model
Epoch 18: Loss improved from 1.124705 to 1.124222 - > Saving model
Epoch 24: Loss improved from 1.124222 to 1.121955 - > Saving model
Epoch 29: Loss improved from 1.121955 to 1.108511 - > Saving model
Epoch 38: Loss improved from 1.108511 to 1.104313 - > Saving model
Epoch 00060: reducing learning rate of group 0 to 1.0000e-04.
Epoch 60: Loss improved from 1.104313 to 1.093644 - > Saving model
Epoch 61: Loss improved from 1.093644 to 1.091090 - > Saving model
Epoch 67: Loss improved from 1.091090 to 1.090775 - > Saving model
Epoch 68: Loss improved from 1.090775 to 1.088622 - > Saving model
Epoch 72: Loss improved from 1.088622 to 1.087777 - > Saving model
Epoch 84: Loss improved from 1.087777 to 1.087255 - > Saving model
Epoch 00106: reducing learning rate of group 0 to 1.0000e-05.
Epoch 106: Loss improved from 1.087255 to 1.086945 - > Saving model
Epoch 110: Loss improved from 1.086945 to 1.086313 - > Saving model
Epoch 111: Loss improved from 1.086313 to 1.086281 - > Saving model
Epoch 112: Loss improved from 1.086281 to 1.085714 - > Saving model
Epoch 00134: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00155: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00176: reducing learning rate of group 0 to 1.0000e-08.
Epoch 204: Loss improved from 1.085714 to 1.085461 - > Saving model
Epoch 304: Loss did not improve for 100 epochs, stopping training
Epoch 304, final validation loss: 1.08802909710828
