Using device: cuda:0
Using configuration gcn-3250-test-film
Dilations: [1, 5, 25, 125, 625, 3125]
Configuration name: gcn-3250-test-film
Receptive field: 156241 samples or 3255.0 ms
Parameters: 431.872 k
Using losses: STFTLoss and SmoothL1Loss
Total dataset samples: 690
Training model for 1000 epochs, current epoch 0
Epoch 0: Loss improved from  inf to 1.209825 - > Saving model
Epoch 1: Loss improved from 1.209825 to 1.109646 - > Saving model
Epoch 2: Loss improved from 1.109646 to 1.045759 - > Saving model
Epoch 3: Loss improved from 1.045759 to 1.021846 - > Saving model
Epoch 5: Loss improved from 1.021846 to 0.991948 - > Saving model
Epoch 6: Loss improved from 0.991948 to 0.967024 - > Saving model
Epoch 8: Loss improved from 0.967024 to 0.949158 - > Saving model
Epoch 9: Loss improved from 0.949158 to 0.944848 - > Saving model
Epoch 11: Loss improved from 0.944848 to 0.932851 - > Saving model
Epoch 12: Loss improved from 0.932851 to 0.926377 - > Saving model
Epoch 15: Loss improved from 0.926377 to 0.914218 - > Saving model
Epoch 18: Loss improved from 0.914218 to 0.910370 - > Saving model
Epoch 19: Loss improved from 0.910370 to 0.905111 - > Saving model
Epoch 21: Loss improved from 0.905111 to 0.898182 - > Saving model
Epoch 26: Loss improved from 0.898182 to 0.883600 - > Saving model
Epoch 27: Loss improved from 0.883600 to 0.881094 - > Saving model
Epoch 29: Loss improved from 0.881094 to 0.878330 - > Saving model
Epoch 34: Loss improved from 0.878330 to 0.877332 - > Saving model
Epoch 35: Loss improved from 0.877332 to 0.860449 - > Saving model
Epoch 40: Loss improved from 0.860449 to 0.860122 - > Saving model
Epoch 47: Loss improved from 0.860122 to 0.857007 - > Saving model
Epoch 48: Loss improved from 0.857007 to 0.856440 - > Saving model
Epoch 50: Loss improved from 0.856440 to 0.853792 - > Saving model
Epoch 53: Loss improved from 0.853792 to 0.841589 - > Saving model
Epoch 63: Loss improved from 0.841589 to 0.835633 - > Saving model
Epoch 67: Loss improved from 0.835633 to 0.835253 - > Saving model
Epoch 70: Loss improved from 0.835253 to 0.831856 - > Saving model
Epoch 71: Loss improved from 0.831856 to 0.826947 - > Saving model
Epoch 83: Loss improved from 0.826947 to 0.817758 - > Saving model
Epoch 92: Loss improved from 0.817758 to 0.815908 - > Saving model
Epoch 100: Loss improved from 0.815908 to 0.809571 - > Saving model
Epoch 110: Loss improved from 0.809571 to 0.806403 - > Saving model
Epoch 120: Loss improved from 0.806403 to 0.799861 - > Saving model
Epoch 122: Loss improved from 0.799861 to 0.796381 - > Saving model
Epoch 141: Loss improved from 0.796381 to 0.794866 - > Saving model
Epoch 145: Loss improved from 0.794866 to 0.792804 - > Saving model
Epoch 148: Loss improved from 0.792804 to 0.792792 - > Saving model
Epoch 154: Loss improved from 0.792792 to 0.792262 - > Saving model
Epoch 162: Loss improved from 0.792262 to 0.790440 - > Saving model
Epoch 170: Loss improved from 0.790440 to 0.788345 - > Saving model
Epoch 176: Loss improved from 0.788345 to 0.786835 - > Saving model
Epoch 184: Loss improved from 0.786835 to 0.784968 - > Saving model
Epoch 188: Loss improved from 0.784968 to 0.780961 - > Saving model
Epoch 206: Loss improved from 0.780961 to 0.779581 - > Saving model
Epoch 214: Loss improved from 0.779581 to 0.771614 - > Saving model
Epoch 00236: reducing learning rate of group 0 to 1.0000e-04.
Epoch 236: Loss improved from 0.771614 to 0.767309 - > Saving model
Epoch 237: Loss improved from 0.767309 to 0.765078 - > Saving model
Epoch 238: Loss improved from 0.765078 to 0.764037 - > Saving model
Epoch 239: Loss improved from 0.764037 to 0.762530 - > Saving model
Epoch 240: Loss improved from 0.762530 to 0.761698 - > Saving model
Epoch 248: Loss improved from 0.761698 to 0.761240 - > Saving model
Epoch 255: Loss improved from 0.761240 to 0.760507 - > Saving model
Epoch 264: Loss improved from 0.760507 to 0.760324 - > Saving model
Epoch 268: Loss improved from 0.760324 to 0.758620 - > Saving model
Epoch 279: Loss improved from 0.758620 to 0.757776 - > Saving model
Epoch 293: Loss improved from 0.757776 to 0.757764 - > Saving model
Epoch 297: Loss improved from 0.757764 to 0.756072 - > Saving model
Epoch 00319: reducing learning rate of group 0 to 1.0000e-05.
Epoch 321: Loss improved from 0.756072 to 0.755808 - > Saving model
Epoch 328: Loss improved from 0.755808 to 0.754904 - > Saving model
Epoch 00350: reducing learning rate of group 0 to 1.0000e-06.
Epoch 363: Loss improved from 0.754904 to 0.754336 - > Saving model
Epoch 00385: reducing learning rate of group 0 to 1.0000e-07.
Epoch 393: Loss improved from 0.754336 to 0.754223 - > Saving model
Epoch 00415: reducing learning rate of group 0 to 1.0000e-08.
Epoch 493: Loss did not improve for 100 epochs, stopping training
Epoch 493, final validation loss: 0.7571036745520199
