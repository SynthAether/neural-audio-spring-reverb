Using device: cuda:0
Using configuration gcn-2750
Configuration name: gcn-2750
Receptive field: 132861 samples or 2767.9 ms
Parameters: 152.320 k
Using losses: STFTLoss and SmoothL1Loss
Total dataset samples: 690
Training model for 1000 epochs, current epoch 0
Epoch 0: Loss improved from  inf to 1.159985 - > Saving model
Epoch 1: Loss improved from 1.159985 to 1.155121 - > Saving model
Epoch 2: Loss improved from 1.155121 to 1.133286 - > Saving model
Epoch 3: Loss improved from 1.133286 to 1.104284 - > Saving model
Epoch 7: Loss improved from 1.104284 to 1.093965 - > Saving model
Epoch 8: Loss improved from 1.093965 to 1.078859 - > Saving model
Epoch 16: Loss improved from 1.078859 to 1.072316 - > Saving model
Epoch 18: Loss improved from 1.072316 to 1.069377 - > Saving model
Epoch 21: Loss improved from 1.069377 to 1.063013 - > Saving model
Epoch 26: Loss improved from 1.063013 to 1.061938 - > Saving model
Epoch 27: Loss improved from 1.061938 to 1.057545 - > Saving model
Epoch 28: Loss improved from 1.057545 to 1.056022 - > Saving model
Epoch 30: Loss improved from 1.056022 to 1.051322 - > Saving model
Epoch 33: Loss improved from 1.051322 to 1.049685 - > Saving model
Epoch 35: Loss improved from 1.049685 to 1.043118 - > Saving model
Epoch 38: Loss improved from 1.043118 to 1.039830 - > Saving model
Epoch 41: Loss improved from 1.039830 to 1.035291 - > Saving model
Epoch 60: Loss improved from 1.035291 to 1.032439 - > Saving model
Epoch 74: Loss improved from 1.032439 to 1.030249 - > Saving model
Epoch 90: Loss improved from 1.030249 to 1.029904 - > Saving model
Epoch 92: Loss improved from 1.029904 to 1.028345 - > Saving model
Epoch 101: Loss improved from 1.028345 to 1.025494 - > Saving model
Epoch 118: Loss improved from 1.025494 to 1.025248 - > Saving model
Epoch 122: Loss improved from 1.025248 to 1.024536 - > Saving model
Epoch 00144: reducing learning rate of group 0 to 1.0000e-04.
Epoch 144: Loss improved from 1.024536 to 1.020726 - > Saving model
Epoch 146: Loss improved from 1.020726 to 1.018136 - > Saving model
Epoch 00168: reducing learning rate of group 0 to 1.0000e-05.
Epoch 177: Loss improved from 1.018136 to 1.018035 - > Saving model
Epoch 00189: reducing learning rate of group 0 to 1.0000e-06.
Epoch 189: Loss improved from 1.018035 to 1.017850 - > Saving model
Epoch 00211: reducing learning rate of group 0 to 1.0000e-07.
Epoch 214: Loss improved from 1.017850 to 1.017782 - > Saving model
Epoch 00232: reducing learning rate of group 0 to 1.0000e-08.
Epoch 314: Loss did not improve for 100 epochs, stopping training
Epoch 314, final validation loss: 1.0225490436834448
